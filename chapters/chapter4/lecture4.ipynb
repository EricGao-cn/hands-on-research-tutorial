{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf3zMvF2l-Fn"
      },
      "source": [
        "### 1. Tensor\n",
        "我们将从最基本的张量开始。首先，浏览官方张量教程[这里](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)。\n",
        "\n",
        "> 张量是一种特殊的数据结构，与数组和矩阵非常相似。在PyTorch中，我们使用张量对模型的输入和输出以及模型的参数进行编码。张量与NumPy的 ndarray 类似，不同之处在于张量可以在GPU或其他专用硬件上运行以加速计算。如果您熟悉 ndarrays，那么您就会熟悉Tensor API。如果没有，请按照此下面的问题进行操作。最好可以不看答案操作一遍，先思考一下，再去搜索一下，最后比对一下正确的操作。这样子效果是最好的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q6rCGrecBBuY"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJg3x_jFLXgp"
      },
      "source": [
        "1. 将二维列表 [[5,3], [0,9]] 转换为一个张量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o9lTGGkvLNvJ"
      },
      "outputs": [],
      "source": [
        "data = [[5, 3], [0, 9]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWPho5cJLmzA"
      },
      "source": [
        "2. 使用区间 [0, 1) 上均匀分布的随机数创建形状 (5, 4) 的张量“t”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dwdJxM-XLo4l"
      },
      "outputs": [],
      "source": [
        "t = torch.rand((5,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3-cxcyLvDJ"
      },
      "source": [
        "3. 找出张量“t”所在的设备及其数据类型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kRPyprDMc1N",
        "outputId": "3a43e42c-965e-4d07-c81b-eccd5b9d8cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(t.device) # cpu\n",
        "\n",
        "print(t.dtype) # float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEZEMKXpL6ON"
      },
      "source": [
        "4. 创建形状 (4,4) 和 (4,4) 的两个随机张量，分别称为“u”和“v”。将它们连接起来形成形状为 (8, 4) 的张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj7ksR69Mkh0",
        "outputId": "9492d01a-a733-45ea-c4af-a8e0271a32e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4])\n"
          ]
        }
      ],
      "source": [
        "u = torch.randn((4,4))\n",
        "v = torch.randn((4,4))\n",
        "print(torch.concat((u,v), dim=0).shape) # torch.Size([8, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TzX8BNKL-1y"
      },
      "source": [
        "5. 连接 u 和 v 以创建形状 (2, 4, 4) 的张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tk2CDLGMoQq",
        "outputId": "c25daebd-a360-441d-f4b4-40bf50899860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 4])\n"
          ]
        }
      ],
      "source": [
        "print(torch.stack((u,v), dim=0).shape) # torch.Size([2, 4, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYdfN7TKMDf-"
      },
      "source": [
        "6. 连接 u 和 v 形成一个张量，称为形状 (4, 4, 2) 的 w。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q10UET4NMqzf",
        "outputId": "0980bb4f-181d-47e5-950a-c802299f6db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "w = torch.stack((u,v), dim=2)\n",
        "print(w.shape) # torch.Size([4, 4, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stR-Or2jMI8e"
      },
      "source": [
        "7. 索引 w 位于 3, 3, 0。将该元素称为“e”。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xNmo0-L5MtNb"
      },
      "outputs": [],
      "source": [
        "e = w[3,3,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXjIhEQxMPBt"
      },
      "source": [
        "8. 会在 u 或 v 的哪一个中找到 w？并核实。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y1zAxuJM5M-",
        "outputId": "4d1bb7ab-3965-4c97-ab20-b4ecee492782"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# in u\n",
        "w[3,3,0] == u[3,3] # True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rZPsa-4MSWC"
      },
      "source": [
        "9. 创建一个形状为 (4, 3) 的全为 1 的张量 ‘a’。对 ‘a’ 进行元素级别的自乘操作。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSjcPCOaM_aa",
        "outputId": "35415e9b-b618-45f0-b3d7-648e08bfac40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "a = torch.ones((4,3))\n",
        "a * a # tensor([[1., 1., 1.],[1., 1., 1.],[1., 1., 1.],[1., 1., 1.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OR05FJOMVf_"
      },
      "source": [
        "10. 向“a”添加一个额外的维度（新的第 0 维度）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osk8Cj0cNCUf",
        "outputId": "534f0769-68b4-4170-d46b-ad777c8de2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 3])\n"
          ]
        }
      ],
      "source": [
        "print(torch.unsqueeze(a, 0).shape) # torch.Size([1, 4, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWxmW68kMXdN"
      },
      "source": [
        "11. 执行 a 与转置矩阵的乘法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyfW3pN6NEnv",
        "outputId": "8bd4dd8f-834c-4a94-c93d-27f09aa11df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "a @ a.T # tensor([3., 3., 3., 3.],[3., 3., 3., 3.],[3., 3., 3., 3.],[3.,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpZl-U8ZMZ4Y"
      },
      "source": [
        "12. a.mul(a) 会产生什么结果？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vvgoz80iNHKl"
      },
      "outputs": [],
      "source": [
        "# 元素乘法，与#9相同"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-R7_MakNXrs"
      },
      "source": [
        "13. a.matmul(a.T) 会产生什么结果？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vb4ENaw4L4nH"
      },
      "outputs": [],
      "source": [
        "# 矩阵乘法又称为点积，与 #11 相同"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2GxhgSKNdZs"
      },
      "source": [
        "14. What would a.mul(a.T) result in?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lhcIBCu0Ngx1"
      },
      "outputs": [],
      "source": [
        "# 错误；尺寸不匹配。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5EoNhQfNlst"
      },
      "source": [
        "15. 猜猜下面会打印什么。验证一下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdFZJ7b-Nld0",
        "outputId": "b50218d7-104e-4cf4-ceee-0b2d5e921aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "n = t.numpy()\n",
        "n[0] = 2\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_kBM2hHN3g9"
      },
      "source": [
        "16. 下面会打印什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AOuR0xdsN_Pv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782f61ee-3858-4e93-adcd-e73b84b8de24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "t = torch.tensor([2., 1., 1., 1., 1.])\n",
        "t.add(2)\n",
        "t.add_(1)\n",
        "print(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5CSkN-4l-Ft"
      },
      "source": [
        "### 2.Autograd 和神经网络\n",
        "接下来，我们学习[自动梯度](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)教程和[神经网络](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)教程。\n",
        "\n",
        "神经网络(NN) 是对某些输入数据执行的嵌套函数的集合。这些函数由参数（由权重和偏差组成）定义，这些参数在PyTorch中存储在张量中。可以使用 torch.nn 包构建神经网络。\n",
        "\n",
        "训练神经网络分两步进行：\n",
        "\n",
        "- 前向传播：在前向传播中，神经网络对正确的输出做出最佳猜测。它通过每个函数运行输入数据来进行猜测。\n",
        "- 反向传播：在反向传播中，神经网络根据其猜测的误差按比例调整其参数。它通过从输出向后遍历、收集误差相对于函数参数（梯度）的导数并使用梯度下降来优化参数来实现这一点。\n",
        "\n",
        "更一般地，神经网络的典型训练过程如下：\n",
        "\n",
        "- 定义具有一些可学习参数（或权重）的神经网络\n",
        "- 迭代输入数据集\n",
        "- 通过网络处理输入\n",
        "- 计算损失（输出距离正确还有多远）\n",
        "- 将梯度传播回网络参数\n",
        "- 更新网络的权重，通常使用简单的更新规则：权重=权重-学习率梯度\n",
        "\n",
        "有了这些教程，我们就可以尝试以下练习了！假设我们有以下起始代码，将下面这段代码复制到你的编辑器中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5xipoh0l-Ft",
        "outputId": "842f1b52-e25c-4988-e5df-6b1c5e0c3a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYg9qiMBl-Ft"
      },
      "source": [
        "17. 使用数据对模型进行前向传递并将其保存为 `preds`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QRTtOj7Il-Ft"
      },
      "outputs": [],
      "source": [
        "preds = model(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUiaJIHLl-Ft"
      },
      "source": [
        "18. `preds` 的形状应该是什么？验证你的猜测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj3cJjbKl-Fw",
        "outputId": "0d72f74f-d13c-4687-9fb7-3c1afeff4d7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# It should be 1 x 1000\n",
        "preds.shape # torch.Size([1, 1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf7wuL0Jl-Fw"
      },
      "source": [
        "19. 将 `resnet18` 的 `conv1` 属性的权重参数保存为 `w`。打印 `w` 因为我们稍后需要它（请注意，我的 `w` 不会与你的相同）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QTwsIXCBl-Fx",
        "outputId": "2d7daf91-6df5-4c7c-f7b6-6d171d7c059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
            "            1.7083e-02, -1.2694e-02],\n",
            "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
            "           -1.2907e-01,  3.7424e-03],\n",
            "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
            "            2.5632e-01,  6.3573e-02],\n",
            "          ...,\n",
            "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
            "           -4.2058e-01, -2.5781e-01],\n",
            "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
            "            3.9359e-01,  1.6606e-01],\n",
            "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
            "           -8.2230e-02, -5.7828e-03]],\n",
            "\n",
            "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
            "            6.6221e-04, -2.5743e-02],\n",
            "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
            "           -1.6051e-01, -1.2826e-03],\n",
            "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
            "            3.6887e-01,  1.2455e-01],\n",
            "          ...,\n",
            "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
            "           -5.7080e-01, -3.6552e-01],\n",
            "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
            "            4.8276e-01,  1.9867e-01],\n",
            "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
            "           -7.7248e-02,  7.2183e-04]],\n",
            "\n",
            "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
            "            3.3655e-02, -2.0102e-02],\n",
            "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
            "           -1.2980e-01, -2.7975e-02],\n",
            "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
            "            1.0433e-01,  1.8413e-02],\n",
            "          ...,\n",
            "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
            "           -2.5760e-01, -1.5451e-01],\n",
            "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
            "            2.4345e-01,  1.1796e-01],\n",
            "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
            "           -1.1754e-01, -3.8350e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
            "           -2.5158e-02, -4.7945e-02],\n",
            "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
            "            1.4287e-01,  1.2312e-01],\n",
            "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
            "            8.0324e-02,  1.1715e-01],\n",
            "          ...,\n",
            "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
            "           -1.1155e-01, -4.9556e-02],\n",
            "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
            "           -2.3320e-02, -2.9474e-02],\n",
            "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
            "            3.5346e-02,  1.1280e-02]],\n",
            "\n",
            "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
            "            4.0423e-02, -1.4439e-02],\n",
            "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
            "            2.6905e-01,  2.0935e-01],\n",
            "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
            "            1.6538e-01,  1.7946e-01],\n",
            "          ...,\n",
            "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
            "           -2.1493e-01, -1.0320e-01],\n",
            "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
            "           -6.9876e-02, -4.9841e-02],\n",
            "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
            "            6.0968e-02,  4.1198e-02]],\n",
            "\n",
            "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
            "            2.2707e-02, -4.5983e-02],\n",
            "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
            "            2.2970e-01,  1.6694e-01],\n",
            "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
            "            1.3216e-01,  1.3579e-01],\n",
            "          ...,\n",
            "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
            "           -1.5609e-01, -7.5974e-02],\n",
            "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
            "           -6.1550e-02, -4.4555e-02],\n",
            "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
            "            2.5221e-02,  7.4257e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
            "           -1.0905e-07, -8.3421e-08],\n",
            "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
            "           -4.3836e-08, -3.0538e-09],\n",
            "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
            "           -1.0951e-09,  4.2442e-08],\n",
            "          ...,\n",
            "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
            "           -4.7666e-08, -1.3265e-08],\n",
            "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
            "            1.0628e-07,  9.3316e-08],\n",
            "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
            "            1.7710e-07,  1.7166e-07]],\n",
            "\n",
            "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
            "           -1.3309e-07, -1.0820e-07],\n",
            "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
            "           -6.7022e-08, -2.2574e-08],\n",
            "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
            "           -7.9591e-09,  3.9750e-08],\n",
            "          ...,\n",
            "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
            "           -5.9930e-08, -1.8247e-08],\n",
            "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
            "            4.1781e-08,  4.5901e-08],\n",
            "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
            "            8.7550e-08,  9.8837e-08]],\n",
            "\n",
            "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
            "           -2.6217e-08, -1.5649e-08],\n",
            "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
            "            7.1450e-08,  9.7615e-08],\n",
            "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
            "            1.3487e-07,  1.6449e-07],\n",
            "          ...,\n",
            "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
            "            6.8382e-08,  1.1367e-07],\n",
            "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
            "            1.1723e-07,  1.4394e-07],\n",
            "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
            "            1.3333e-07,  1.5844e-07]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
            "           -2.2114e-02, -4.2214e-02],\n",
            "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
            "            5.9254e-02,  2.9958e-02],\n",
            "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
            "            4.1422e-02,  2.3134e-02],\n",
            "          ...,\n",
            "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
            "            2.2274e-02, -5.4993e-03],\n",
            "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
            "           -7.5033e-03, -5.9736e-02],\n",
            "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
            "            8.4406e-03, -5.0019e-02]],\n",
            "\n",
            "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
            "           -3.2708e-02, -4.1060e-02],\n",
            "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
            "            4.6687e-02,  3.3248e-02],\n",
            "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
            "            3.6478e-02,  3.1291e-02],\n",
            "          ...,\n",
            "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
            "            2.8894e-02,  1.3984e-02],\n",
            "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
            "            1.6197e-02, -1.2493e-02],\n",
            "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
            "            4.0119e-02, -5.3310e-03]],\n",
            "\n",
            "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
            "           -3.4818e-02, -4.9945e-02],\n",
            "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
            "            5.3438e-02,  4.0169e-02],\n",
            "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
            "            2.6298e-02,  2.5489e-02],\n",
            "          ...,\n",
            "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
            "           -6.2689e-03, -8.4638e-03],\n",
            "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
            "           -1.4296e-02, -3.2419e-02],\n",
            "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
            "            1.2996e-02, -8.3417e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
            "            1.2820e-02,  1.8142e-02],\n",
            "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
            "            4.5889e-02,  5.2383e-02],\n",
            "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
            "            3.7806e-02,  2.6944e-02],\n",
            "          ...,\n",
            "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
            "            1.8313e-02,  1.6057e-02],\n",
            "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
            "            2.2857e-02,  6.5783e-04],\n",
            "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
            "            1.8770e-02,  1.5624e-02]],\n",
            "\n",
            "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
            "            9.2341e-03,  1.5751e-02],\n",
            "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
            "            2.6264e-02,  2.3773e-02],\n",
            "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
            "            3.2477e-02,  1.1980e-02],\n",
            "          ...,\n",
            "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
            "            2.4658e-02,  1.2893e-02],\n",
            "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
            "            3.9210e-02,  9.6696e-03],\n",
            "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
            "            2.7253e-02,  1.7735e-02]],\n",
            "\n",
            "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
            "           -2.6154e-02, -2.3525e-02],\n",
            "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
            "           -2.3337e-02, -3.7312e-02],\n",
            "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
            "           -8.3744e-03, -4.0615e-02],\n",
            "          ...,\n",
            "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
            "           -8.7267e-03, -2.3526e-02],\n",
            "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
            "            1.4814e-02, -1.4487e-02],\n",
            "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
            "           -1.3049e-02, -2.4368e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
            "            1.4870e-02, -1.7298e-02],\n",
            "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
            "           -5.5036e-05, -3.0162e-02],\n",
            "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
            "           -7.2041e-02, -6.2474e-02],\n",
            "          ...,\n",
            "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
            "            1.4344e-01,  5.5145e-02],\n",
            "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
            "           -4.1518e-03, -3.8118e-02],\n",
            "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
            "           -1.4687e-01, -9.0890e-02]],\n",
            "\n",
            "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
            "            3.0229e-03,  1.1216e-03],\n",
            "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
            "           -2.0227e-02, -9.1878e-03],\n",
            "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
            "           -1.0735e-01, -6.2971e-02],\n",
            "          ...,\n",
            "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
            "            2.6202e-01,  1.3491e-01],\n",
            "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
            "            9.0893e-02, -1.7392e-03],\n",
            "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
            "           -1.0095e-01, -9.7920e-02]],\n",
            "\n",
            "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
            "            2.0666e-03,  1.3902e-02],\n",
            "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
            "           -5.0725e-03,  4.0505e-03],\n",
            "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
            "           -7.4489e-02, -5.7533e-02],\n",
            "          ...,\n",
            "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
            "            1.2017e-01,  7.1998e-02],\n",
            "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
            "            2.2142e-02, -1.0083e-02],\n",
            "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
            "           -7.1195e-02, -6.6788e-02]]]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "w = model.conv1.weight\n",
        "print(w) # tensor([[[[-1.0419e-02,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOO9INLgl-Fx"
      },
      "source": [
        "20. `w` 的 `grad` 属性应该是什么？请验证。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQbEXeNXl-Fx",
        "outputId": "d852be5b-4027-4684-ef23-fc3c2d7624c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Should be None. That’s because we haven’t run backward yet.\n",
        "print(w.grad) # None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWUi2NRAl-Fx"
      },
      "source": [
        "21. 创建一个[交叉熵](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)损失对象，并用它来使用 `labels` 和 `preds` 计算损失，保存为 `loss`。打印 `loss`，因为我们稍后需要它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsZOYs60l-Fx",
        "outputId": "9400df3d-4b34-452c-da8e-f4f7cb96f517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3577.2236, grad_fn=<DivBackward1>)\n"
          ]
        }
      ],
      "source": [
        "ce = torch.nn.CrossEntropyLoss()\n",
        "loss = ce(preds, labels)\n",
        "print(loss) # tensor(3631.9521, grad_fn=<DivBackward1>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEJmQ7Xfl-Fx"
      },
      "source": [
        "22. 打印最后一次产生 `loss` 损失的数学运算。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTBF63Nwl-Fx",
        "outputId": "5e1831b1-275f-425d-89de-d58baf78131f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<DivBackward1 object at 0x7a3343017b20>\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn) # <DivBackward1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpPqwKFvl-Fx"
      },
      "source": [
        "23. 执行反向传播。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uIWJNZ6_l-Fx"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI-9wYdtl-Fx"
      },
      "source": [
        "24. `w` 应该改变吗？还可以检查 #19 的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sNfXiPJ9l-Fy",
        "outputId": "f7e05549-0422-4a86-904b-601fdc0430f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
            "            1.7083e-02, -1.2694e-02],\n",
            "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
            "           -1.2907e-01,  3.7424e-03],\n",
            "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
            "            2.5632e-01,  6.3573e-02],\n",
            "          ...,\n",
            "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
            "           -4.2058e-01, -2.5781e-01],\n",
            "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
            "            3.9359e-01,  1.6606e-01],\n",
            "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
            "           -8.2230e-02, -5.7828e-03]],\n",
            "\n",
            "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
            "            6.6221e-04, -2.5743e-02],\n",
            "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
            "           -1.6051e-01, -1.2826e-03],\n",
            "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
            "            3.6887e-01,  1.2455e-01],\n",
            "          ...,\n",
            "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
            "           -5.7080e-01, -3.6552e-01],\n",
            "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
            "            4.8276e-01,  1.9867e-01],\n",
            "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
            "           -7.7248e-02,  7.2183e-04]],\n",
            "\n",
            "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
            "            3.3655e-02, -2.0102e-02],\n",
            "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
            "           -1.2980e-01, -2.7975e-02],\n",
            "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
            "            1.0433e-01,  1.8413e-02],\n",
            "          ...,\n",
            "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
            "           -2.5760e-01, -1.5451e-01],\n",
            "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
            "            2.4345e-01,  1.1796e-01],\n",
            "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
            "           -1.1754e-01, -3.8350e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
            "           -2.5158e-02, -4.7945e-02],\n",
            "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
            "            1.4287e-01,  1.2312e-01],\n",
            "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
            "            8.0324e-02,  1.1715e-01],\n",
            "          ...,\n",
            "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
            "           -1.1155e-01, -4.9556e-02],\n",
            "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
            "           -2.3320e-02, -2.9474e-02],\n",
            "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
            "            3.5346e-02,  1.1280e-02]],\n",
            "\n",
            "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
            "            4.0423e-02, -1.4439e-02],\n",
            "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
            "            2.6905e-01,  2.0935e-01],\n",
            "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
            "            1.6538e-01,  1.7946e-01],\n",
            "          ...,\n",
            "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
            "           -2.1493e-01, -1.0320e-01],\n",
            "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
            "           -6.9876e-02, -4.9841e-02],\n",
            "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
            "            6.0968e-02,  4.1198e-02]],\n",
            "\n",
            "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
            "            2.2707e-02, -4.5983e-02],\n",
            "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
            "            2.2970e-01,  1.6694e-01],\n",
            "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
            "            1.3216e-01,  1.3579e-01],\n",
            "          ...,\n",
            "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
            "           -1.5609e-01, -7.5974e-02],\n",
            "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
            "           -6.1550e-02, -4.4555e-02],\n",
            "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
            "            2.5221e-02,  7.4257e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
            "           -1.0905e-07, -8.3421e-08],\n",
            "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
            "           -4.3836e-08, -3.0538e-09],\n",
            "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
            "           -1.0951e-09,  4.2442e-08],\n",
            "          ...,\n",
            "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
            "           -4.7666e-08, -1.3265e-08],\n",
            "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
            "            1.0628e-07,  9.3316e-08],\n",
            "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
            "            1.7710e-07,  1.7166e-07]],\n",
            "\n",
            "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
            "           -1.3309e-07, -1.0820e-07],\n",
            "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
            "           -6.7022e-08, -2.2574e-08],\n",
            "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
            "           -7.9591e-09,  3.9750e-08],\n",
            "          ...,\n",
            "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
            "           -5.9930e-08, -1.8247e-08],\n",
            "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
            "            4.1781e-08,  4.5901e-08],\n",
            "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
            "            8.7550e-08,  9.8837e-08]],\n",
            "\n",
            "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
            "           -2.6217e-08, -1.5649e-08],\n",
            "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
            "            7.1450e-08,  9.7615e-08],\n",
            "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
            "            1.3487e-07,  1.6449e-07],\n",
            "          ...,\n",
            "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
            "            6.8382e-08,  1.1367e-07],\n",
            "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
            "            1.1723e-07,  1.4394e-07],\n",
            "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
            "            1.3333e-07,  1.5844e-07]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
            "           -2.2114e-02, -4.2214e-02],\n",
            "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
            "            5.9254e-02,  2.9958e-02],\n",
            "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
            "            4.1422e-02,  2.3134e-02],\n",
            "          ...,\n",
            "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
            "            2.2274e-02, -5.4993e-03],\n",
            "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
            "           -7.5033e-03, -5.9736e-02],\n",
            "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
            "            8.4406e-03, -5.0019e-02]],\n",
            "\n",
            "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
            "           -3.2708e-02, -4.1060e-02],\n",
            "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
            "            4.6687e-02,  3.3248e-02],\n",
            "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
            "            3.6478e-02,  3.1291e-02],\n",
            "          ...,\n",
            "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
            "            2.8894e-02,  1.3984e-02],\n",
            "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
            "            1.6197e-02, -1.2493e-02],\n",
            "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
            "            4.0119e-02, -5.3310e-03]],\n",
            "\n",
            "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
            "           -3.4818e-02, -4.9945e-02],\n",
            "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
            "            5.3438e-02,  4.0169e-02],\n",
            "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
            "            2.6298e-02,  2.5489e-02],\n",
            "          ...,\n",
            "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
            "           -6.2689e-03, -8.4638e-03],\n",
            "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
            "           -1.4296e-02, -3.2419e-02],\n",
            "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
            "            1.2996e-02, -8.3417e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
            "            1.2820e-02,  1.8142e-02],\n",
            "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
            "            4.5889e-02,  5.2383e-02],\n",
            "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
            "            3.7806e-02,  2.6944e-02],\n",
            "          ...,\n",
            "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
            "            1.8313e-02,  1.6057e-02],\n",
            "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
            "            2.2857e-02,  6.5783e-04],\n",
            "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
            "            1.8770e-02,  1.5624e-02]],\n",
            "\n",
            "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
            "            9.2341e-03,  1.5751e-02],\n",
            "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
            "            2.6264e-02,  2.3773e-02],\n",
            "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
            "            3.2477e-02,  1.1980e-02],\n",
            "          ...,\n",
            "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
            "            2.4658e-02,  1.2893e-02],\n",
            "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
            "            3.9210e-02,  9.6696e-03],\n",
            "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
            "            2.7253e-02,  1.7735e-02]],\n",
            "\n",
            "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
            "           -2.6154e-02, -2.3525e-02],\n",
            "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
            "           -2.3337e-02, -3.7312e-02],\n",
            "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
            "           -8.3744e-03, -4.0615e-02],\n",
            "          ...,\n",
            "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
            "           -8.7267e-03, -2.3526e-02],\n",
            "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
            "            1.4814e-02, -1.4487e-02],\n",
            "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
            "           -1.3049e-02, -2.4368e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
            "            1.4870e-02, -1.7298e-02],\n",
            "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
            "           -5.5036e-05, -3.0162e-02],\n",
            "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
            "           -7.2041e-02, -6.2474e-02],\n",
            "          ...,\n",
            "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
            "            1.4344e-01,  5.5145e-02],\n",
            "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
            "           -4.1518e-03, -3.8118e-02],\n",
            "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
            "           -1.4687e-01, -9.0890e-02]],\n",
            "\n",
            "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
            "            3.0229e-03,  1.1216e-03],\n",
            "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
            "           -2.0227e-02, -9.1878e-03],\n",
            "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
            "           -1.0735e-01, -6.2971e-02],\n",
            "          ...,\n",
            "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
            "            2.6202e-01,  1.3491e-01],\n",
            "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
            "            9.0893e-02, -1.7392e-03],\n",
            "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
            "           -1.0095e-01, -9.7920e-02]],\n",
            "\n",
            "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
            "            2.0666e-03,  1.3902e-02],\n",
            "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
            "           -5.0725e-03,  4.0505e-03],\n",
            "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
            "           -7.4489e-02, -5.7533e-02],\n",
            "          ...,\n",
            "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
            "            1.2017e-01,  7.1998e-02],\n",
            "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
            "            2.2142e-02, -1.0083e-02],\n",
            "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
            "           -7.1195e-02, -6.6788e-02]]]], requires_grad=True) cpu torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(w, w.device, w.dtype)\n",
        "# No,可以对比19的输出，意味着，在执行反向传播之后，w还没发生变化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygo-iNdWl-Fy"
      },
      "source": [
        "25. `w` 的 `grad` 属性会与 #20 不同吗？并验证。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sh0wKwqDl-Fy",
        "outputId": "7e815105-68e7-4bdc-cade-cd5eefee8549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 1.5557e+01,  3.2234e+01,  1.3943e+01,  ...,  1.2458e+01,\n",
            "           -3.0728e+01, -1.3171e+01],\n",
            "          [-3.7709e+00,  1.5890e+00,  1.2804e+01,  ..., -1.3437e+01,\n",
            "           -1.9187e+01, -2.5725e+01],\n",
            "          [-3.0219e+01,  4.5103e+01, -2.0667e+01,  ..., -2.5583e+01,\n",
            "           -1.5257e+00,  2.2881e+01],\n",
            "          ...,\n",
            "          [ 2.5067e+01,  1.3528e+01,  2.2823e+01,  ...,  1.5760e+01,\n",
            "            4.5022e+01,  2.0843e+01],\n",
            "          [ 3.1609e+01,  2.1389e+01,  5.0992e-02,  ...,  3.7038e+00,\n",
            "           -2.3746e+00,  7.8445e+00],\n",
            "          [-5.1651e+00,  4.1003e+01,  1.8838e+01,  ...,  5.1312e+01,\n",
            "            2.6850e+01, -1.3850e+00]],\n",
            "\n",
            "         [[-7.3457e+00,  1.3157e+00, -2.7986e+01,  ..., -2.0768e+01,\n",
            "            2.1666e+01, -2.1206e+01],\n",
            "          [-3.5448e+00, -1.7306e+01,  2.4410e+01,  ...,  1.8149e+01,\n",
            "           -3.5010e+01, -1.8431e+01],\n",
            "          [ 1.4952e+01,  3.1402e+00,  1.5348e+01,  ..., -3.4521e+00,\n",
            "           -2.7564e+01, -4.6773e+01],\n",
            "          ...,\n",
            "          [-9.2166e+00,  2.7313e+01,  3.0710e+01,  ..., -8.1654e+00,\n",
            "           -1.3849e+00, -1.6984e+01],\n",
            "          [ 4.2482e+01,  2.6572e+00, -7.3078e+00,  ...,  2.7580e+01,\n",
            "           -4.8912e+00,  1.6635e+00],\n",
            "          [-2.5695e+01, -1.0297e-02,  1.3079e+00,  ..., -3.1778e+01,\n",
            "           -1.1581e+01, -2.0073e+01]],\n",
            "\n",
            "         [[ 9.0621e+00,  1.4527e+01, -1.4474e+01,  ..., -2.5479e+01,\n",
            "            2.1569e+01, -1.5837e+01],\n",
            "          [ 2.4980e+00,  2.8317e+01, -1.0893e+01,  ...,  2.4928e+01,\n",
            "           -3.0741e+01, -2.1033e+01],\n",
            "          [ 2.8137e+01,  7.9067e+00, -7.4641e+00,  ...,  2.4231e+01,\n",
            "           -2.2107e+00, -3.1715e+01],\n",
            "          ...,\n",
            "          [ 3.3242e+01,  1.4290e+00,  4.3641e+00,  ..., -3.3032e+01,\n",
            "           -1.2005e+01,  1.0909e+01],\n",
            "          [-2.0673e+00, -6.0404e+00,  1.6085e+01,  ...,  1.3386e+01,\n",
            "            1.9157e+01,  9.7193e+00],\n",
            "          [ 2.6076e+01,  2.7852e+01,  2.7017e+01,  ..., -2.5078e+01,\n",
            "           -3.1566e+01, -3.2278e+01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4353e+00,  2.3170e-01,  2.1758e+01,  ...,  5.1051e-01,\n",
            "           -8.0826e-01,  7.0065e+01],\n",
            "          [ 5.9882e+00,  7.9608e+00,  1.9167e-01,  ..., -3.9280e+01,\n",
            "            2.7356e+00, -6.0663e+01],\n",
            "          [-3.6904e+01,  4.6270e+01,  1.4055e+01,  ...,  3.4029e+00,\n",
            "           -2.3316e+01,  4.0045e+01],\n",
            "          ...,\n",
            "          [ 2.2745e+01,  2.7256e+01,  1.3023e+01,  ..., -3.2143e+00,\n",
            "           -4.0560e+01, -1.4166e+01],\n",
            "          [-3.4894e+01,  8.3039e-01, -2.3927e+01,  ..., -5.7906e+01,\n",
            "           -6.6757e+01, -7.2474e+00],\n",
            "          [-5.8313e+00, -1.3170e+01, -6.0226e+01,  ..., -1.9844e+01,\n",
            "           -1.7593e+01,  3.5867e+01]],\n",
            "\n",
            "         [[ 4.5626e+00,  1.4048e+01,  4.8733e+01,  ..., -5.1689e+01,\n",
            "            5.1421e+01,  3.5314e+01],\n",
            "          [-2.4688e+01,  4.4115e+00,  3.2747e+01,  ...,  9.1937e+01,\n",
            "           -3.1482e+01,  3.2830e+00],\n",
            "          [-1.8852e+01, -2.1935e+01, -2.4621e+00,  ...,  2.7820e+01,\n",
            "           -4.6451e+01, -1.3962e+01],\n",
            "          ...,\n",
            "          [-2.2699e+01,  1.7146e+01, -4.0084e+01,  ..., -1.1153e+00,\n",
            "            2.5283e+01,  1.9058e+00],\n",
            "          [-5.9170e+01, -9.2688e+00,  2.9034e+01,  ...,  1.9681e+01,\n",
            "           -6.3036e+01, -1.2118e+01],\n",
            "          [-2.0816e+01, -4.2612e+01,  1.4319e+01,  ..., -6.1656e+01,\n",
            "           -4.2340e+00, -3.0648e+01]],\n",
            "\n",
            "         [[-1.5282e+01,  1.9063e+01,  4.2658e+01,  ...,  1.4498e+01,\n",
            "            1.5656e+01, -6.4811e+00],\n",
            "          [-3.5629e+01, -1.5026e+00,  7.7268e+00,  ..., -1.5233e+01,\n",
            "           -5.3124e+01,  4.8740e+00],\n",
            "          [ 3.0680e+01, -1.6825e+01,  1.2437e+01,  ...,  5.5138e+00,\n",
            "            2.8262e+00, -3.7321e+01],\n",
            "          ...,\n",
            "          [-8.1397e+00, -3.6039e+01, -2.9491e+01,  ..., -4.4407e+00,\n",
            "            3.8043e+01, -2.9225e+00],\n",
            "          [ 3.2855e+01, -3.0673e+01,  1.9073e+01,  ..., -5.6463e+01,\n",
            "           -9.6560e+01,  7.6672e+00],\n",
            "          [-3.3518e+01,  8.2473e+00, -1.1064e+01,  ..., -2.0577e+01,\n",
            "            1.4263e+01, -5.4796e+01]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3067e+01, -4.9003e+01, -1.0305e+02,  ..., -9.9088e+01,\n",
            "           -9.1024e+01, -1.0288e+02],\n",
            "          [ 6.8240e+01,  1.0848e+02, -1.1187e+02,  ...,  1.3128e+02,\n",
            "            8.6342e+01,  1.0516e+02],\n",
            "          [-1.5876e+02, -2.0047e-01,  5.1779e+01,  ..., -5.9072e+01,\n",
            "            7.1513e+01, -4.3597e+01],\n",
            "          ...,\n",
            "          [ 4.3282e+01,  4.4334e+01,  8.0061e+01,  ...,  4.1658e+01,\n",
            "            3.5692e+01,  2.1845e+01],\n",
            "          [ 1.0741e+02, -1.6263e+01,  1.2021e+02,  ...,  6.4267e+00,\n",
            "            4.5135e+01, -1.6609e+01],\n",
            "          [-5.5708e+00,  1.4653e+02, -4.4752e+01,  ...,  6.4247e+01,\n",
            "            5.2152e+01,  9.1546e+01]],\n",
            "\n",
            "         [[-5.9852e+01, -9.8125e+01, -1.4697e+02,  ...,  4.5078e+01,\n",
            "            2.4594e+00, -3.6507e+01],\n",
            "          [ 1.4213e+02,  3.3066e+01, -1.1924e+02,  ..., -4.4805e+01,\n",
            "           -1.4622e+02,  4.1601e+01],\n",
            "          [ 6.1152e+01,  7.7009e+01,  2.7237e+01,  ..., -3.4437e+01,\n",
            "            6.6362e+01,  5.3541e+01],\n",
            "          ...,\n",
            "          [ 7.2154e+01, -9.7053e+01, -4.1575e+01,  ..., -9.3138e+01,\n",
            "            6.9641e+01, -8.1181e+01],\n",
            "          [ 1.3511e+02,  1.4246e+02,  4.8005e+01,  ..., -1.8306e+00,\n",
            "           -3.4487e+01, -6.2662e+01],\n",
            "          [-5.1831e+01, -1.5655e+01,  6.7978e+01,  ..., -1.8413e+01,\n",
            "            8.0222e+01,  2.5013e+01]],\n",
            "\n",
            "         [[-6.5705e+01,  3.8002e+01, -5.0648e+01,  ..., -4.9476e+01,\n",
            "           -1.6852e+01, -2.8003e+01],\n",
            "          [ 7.4281e+01,  7.9372e+01,  2.7237e+01,  ..., -9.2073e+01,\n",
            "            7.9074e+01, -5.1708e+01],\n",
            "          [ 8.2392e+00,  3.0002e+01, -2.0292e+01,  ...,  2.7943e+01,\n",
            "            3.4682e+00,  1.0400e+01],\n",
            "          ...,\n",
            "          [ 2.6473e+01,  7.3147e+01, -5.6188e+01,  ..., -1.0669e+01,\n",
            "           -1.0446e-01,  5.8424e+01],\n",
            "          [-3.5844e+00,  5.6853e+01, -4.2339e+01,  ...,  6.7961e+01,\n",
            "           -2.1911e+01,  1.1032e+01],\n",
            "          [ 4.6188e+01,  5.8770e+01, -1.5514e+01,  ...,  6.2381e+01,\n",
            "            5.2741e+01,  1.3520e+02]]],\n",
            "\n",
            "\n",
            "        [[[-2.1438e+01,  2.3171e+01,  4.6761e+01,  ...,  6.2347e+01,\n",
            "            2.4372e+01,  2.7659e+01],\n",
            "          [-3.3705e+01,  1.3560e+01,  2.8595e+01,  ...,  1.3472e+01,\n",
            "           -2.1365e+01,  2.8105e+01],\n",
            "          [ 5.7490e+00, -2.0862e+01, -2.4687e+00,  ...,  2.8499e+01,\n",
            "            1.7780e+01,  2.5706e+01],\n",
            "          ...,\n",
            "          [-4.2300e+01, -1.2800e+01, -6.9572e+01,  ..., -4.7776e+01,\n",
            "           -1.0608e+02,  1.6999e+01],\n",
            "          [ 1.9937e+01, -2.3100e+01, -2.5668e-01,  ..., -3.2295e-01,\n",
            "           -2.8812e+01, -7.2050e+00],\n",
            "          [-5.0535e+01, -4.2109e+01,  5.8389e+00,  ..., -3.0723e+01,\n",
            "            5.4212e+01, -3.7726e+01]],\n",
            "\n",
            "         [[-1.1854e+01, -6.2888e+00, -3.6692e+01,  ...,  1.4879e+01,\n",
            "           -4.6442e+01,  4.3052e+01],\n",
            "          [-1.5323e+01,  7.1432e+01, -1.2936e+01,  ..., -2.6005e+01,\n",
            "           -1.6126e+00, -4.0948e+01],\n",
            "          [ 2.4466e+01,  1.3727e+01,  9.0514e+00,  ...,  9.2415e+01,\n",
            "            6.9337e+00,  1.2163e+01],\n",
            "          ...,\n",
            "          [-2.7832e+01, -2.3254e+01, -9.1434e+01,  ..., -7.1397e+01,\n",
            "           -5.3560e+01, -3.1874e+01],\n",
            "          [ 7.3705e-01,  2.0769e+01, -2.3826e+01,  ..., -2.7052e+00,\n",
            "            1.2960e-01, -2.0417e+01],\n",
            "          [-6.1635e+01,  3.3116e+01, -1.6885e+01,  ..., -1.4165e+01,\n",
            "           -5.2257e+00, -3.2331e+01]],\n",
            "\n",
            "         [[ 3.5385e+01, -4.5435e+01,  2.8973e+01,  ...,  3.0171e+01,\n",
            "           -2.9674e+01,  7.7094e+01],\n",
            "          [-6.2773e+01, -3.2322e+01,  5.6893e+01,  ..., -6.9339e+00,\n",
            "            4.3514e+01,  1.6310e+01],\n",
            "          [-3.3641e+01, -1.0252e+01, -3.8752e+01,  ...,  7.5280e+01,\n",
            "            6.9778e+00, -2.9281e+01],\n",
            "          ...,\n",
            "          [-1.5146e+01, -1.0992e+01, -1.9200e+01,  ..., -4.1307e+00,\n",
            "            5.5864e+01, -1.4332e+00],\n",
            "          [-2.4805e+01, -5.1907e+01, -1.3836e+01,  ...,  6.2005e+01,\n",
            "           -2.3913e+00, -1.1248e+01],\n",
            "          [ 1.4306e+01, -1.9010e+01, -6.0772e-01,  ..., -2.4900e+01,\n",
            "            5.4074e+01,  3.5447e+01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9289e+01, -4.8641e+01, -3.7995e+01,  ..., -8.9115e+01,\n",
            "           -2.7615e+01, -1.6169e+01],\n",
            "          [ 2.8878e+01,  2.6947e+00, -2.0559e+01,  ..., -1.6787e+01,\n",
            "           -6.8092e+00,  2.7948e+00],\n",
            "          [ 1.5936e+01, -4.7931e+01,  4.4811e+00,  ..., -5.5572e+01,\n",
            "           -2.0132e+01, -6.4414e+01],\n",
            "          ...,\n",
            "          [ 4.8966e+01, -4.9869e+01,  3.5510e+01,  ..., -5.5469e+01,\n",
            "            1.0584e+01, -2.1699e+01],\n",
            "          [ 7.5637e+01,  6.9222e+01,  4.9029e+01,  ..., -1.9724e+01,\n",
            "           -1.9952e+00, -3.4261e+01],\n",
            "          [ 2.9236e+01, -4.9083e+01, -1.0531e+01,  ...,  5.6447e+01,\n",
            "            1.0893e+00,  2.2112e+01]],\n",
            "\n",
            "         [[ 2.6162e+01, -1.4645e+01, -2.5496e+01,  ...,  1.3164e+00,\n",
            "           -4.5093e+01, -7.1982e+01],\n",
            "          [ 3.2079e+01,  1.6735e+01,  7.8700e+00,  ..., -2.3015e+01,\n",
            "           -4.3387e+01,  1.5129e+01],\n",
            "          [-1.9611e+01, -1.2036e+01, -4.8221e+01,  ..., -2.6277e+01,\n",
            "           -3.4440e+01,  1.1277e+01],\n",
            "          ...,\n",
            "          [-2.8133e+01, -3.7718e+00, -1.0349e+01,  ..., -1.5540e+01,\n",
            "            1.0199e+01,  1.2504e+01],\n",
            "          [ 2.5651e+01, -1.3625e+01,  4.1907e+01,  ...,  5.5378e+01,\n",
            "           -1.5339e+00, -2.1796e+01],\n",
            "          [-1.2849e+00, -1.5294e+01,  1.2138e+01,  ..., -6.7829e+01,\n",
            "           -2.1482e+01,  3.9038e+00]],\n",
            "\n",
            "         [[-2.2646e+01, -1.5719e+01, -5.5042e+01,  ..., -3.4769e+01,\n",
            "           -9.1904e+01, -4.1345e+01],\n",
            "          [ 3.4405e+01,  8.5592e+00, -4.0503e+01,  ...,  1.3082e+01,\n",
            "           -6.5856e+00, -2.8318e+01],\n",
            "          [-1.5126e+01, -3.2779e+01,  2.9998e+00,  ..., -1.3221e+01,\n",
            "           -4.4954e+01,  1.1306e+01],\n",
            "          ...,\n",
            "          [ 1.8093e+01,  2.4699e+01,  7.7242e+00,  ..., -2.0924e+01,\n",
            "           -5.7939e+01, -3.2283e+01],\n",
            "          [ 6.7801e+01, -1.1472e+01,  5.3333e+00,  ...,  1.4395e+01,\n",
            "           -2.2840e+01,  5.0579e+01],\n",
            "          [-1.8549e+01,  1.1788e+01, -2.5828e+01,  ..., -1.0907e+01,\n",
            "           -1.5773e+01,  1.9868e+00]]]])\n"
          ]
        }
      ],
      "source": [
        "print(w.grad) # tensor([[[[ 7.0471e+01,  5.9916e+00,...\n",
        "# Yes，意味着参数虽然没变化，但是对应的grad属性发生了变化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvMwaIFKl-Fy"
      },
      "source": [
        "26. `loss` 的 `grad` 属性应该返回什么？验证一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOFN3HLYl-Fy",
        "outputId": "d577271e-0874-4ed0-faa8-7dc92a63e63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-b05af3085b47>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(loss.grad)\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad)\n",
        "# 返回None值，在深度学习中，我们通常会计算损失（loss）并进行反向传播来更新模型的参数。这里提到的“loss”指的是计算出来的损失值，它不是模型参数中的一个叶子节点（叶子节点是指那些需要更新的参数）。\n",
        "\n",
        "# 因为这个损失值不是叶子节点，所以默认情况下，它不会保存反向传播时计算出的梯度。如果我们想要保存这些梯度，就需要调用 loss.retain_grad() 方法来明确告诉系统“即使这个损失值不是叶子节点，也请保留它的梯度”。\n",
        "\n",
        "# 由于我们没有调用这个方法，所以在进行反向传播时，损失值的梯度不会被保存。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdt-0PV0l-Fy"
      },
      "source": [
        "27. `loss` 的 `requires_grad` 属性应该是什么？验证一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTA27a9pl-Fy",
        "outputId": "7128f8eb-838a-4b21-9f7e-feed02d64c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(loss.requires_grad)\n",
        "# True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLjvVCiRl-Fy"
      },
      "source": [
        "28. `labels` 的 `requires_grad` 属性应该是什么？验证一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0petL10vl-Fz",
        "outputId": "3db41749-981f-4d3d-85cf-045df2495e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(labels.requires_grad)\n",
        "# False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmxLJd2fl-Fz"
      },
      "source": [
        "29. 如果你再次执行反向传播会发生什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "11N2HRLMl-Fz"
      },
      "outputs": [],
      "source": [
        "# 会发生运行时错误，因为在第一次调用 .backward() 时，计算图中保存的中间值会被释放，除非我们指定 retain_graph=True。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiOKu8hl-Fz"
      },
      "source": [
        "30. 创建一个学习率 (`lr=1e-2`) 和动量 (`momentum=0.9`) 的 [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) 优化器对象，并执行一步。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "trIqPL3nl-Fz"
      },
      "outputs": [],
      "source": [
        "sgd = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "sgd.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPb_sBWpl-Fz"
      },
      "source": [
        "31. `w` 是否应该改变？检查第19题的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7pqGcyuQl-Fz",
        "outputId": "5d1966fe-adc8-4296-dac3-bfca8dc77fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.6598e-01, -3.2848e-01, -1.4124e-01,  ..., -6.7964e-02,\n",
            "            3.2436e-01,  1.1902e-01],\n",
            "          [ 4.8792e-02, -6.3623e-03, -2.3797e-01,  ..., -1.3687e-01,\n",
            "            6.2791e-02,  2.6099e-01],\n",
            "          [ 2.9525e-01, -3.9194e-01,  5.0215e-01,  ...,  7.7555e-01,\n",
            "            2.7158e-01, -1.6524e-01],\n",
            "          ...,\n",
            "          [-2.7821e-01, -1.1924e-01, -1.5563e-01,  ..., -4.9045e-01,\n",
            "           -8.7080e-01, -4.6624e-01],\n",
            "          [-2.8547e-01, -1.7293e-01,  6.2340e-02,  ...,  3.7680e-01,\n",
            "            4.1734e-01,  8.7614e-02],\n",
            "          [ 3.7914e-02, -4.1371e-01, -2.1246e-01,  ..., -6.6382e-01,\n",
            "           -3.5073e-01,  8.0671e-03]],\n",
            "\n",
            "         [[ 6.2060e-02, -3.9776e-02,  2.4522e-01,  ...,  2.4020e-01,\n",
            "           -2.1600e-01,  1.8632e-01],\n",
            "          [ 8.1134e-02,  2.0667e-01, -3.4863e-01,  ..., -4.9401e-01,\n",
            "            1.8960e-01,  1.8302e-01],\n",
            "          [-1.5035e-01,  6.7018e-02,  2.4862e-01,  ...,  7.4241e-01,\n",
            "            6.4451e-01,  5.9228e-01],\n",
            "          ...,\n",
            "          [ 3.6240e-02, -2.7835e-01, -2.8002e-01,  ..., -3.8013e-01,\n",
            "           -5.5695e-01, -1.9568e-01],\n",
            "          [-3.9196e-01,  2.9003e-02,  1.7275e-01,  ...,  2.7056e-01,\n",
            "            5.3167e-01,  1.8204e-01],\n",
            "          [ 2.6226e-01,  6.7968e-03, -3.0334e-02,  ...,  1.6955e-01,\n",
            "            3.8566e-02,  2.0145e-01]],\n",
            "\n",
            "         [[-9.2653e-02, -1.5443e-01,  1.6595e-01,  ...,  3.4396e-01,\n",
            "           -1.8203e-01,  1.3826e-01],\n",
            "          [-9.5814e-03, -3.0182e-01, -1.6976e-02,  ..., -5.0270e-01,\n",
            "            1.7761e-01,  1.8236e-01],\n",
            "          [-2.7152e-01, -3.0020e-02,  2.9163e-01,  ...,  1.0640e-01,\n",
            "            1.2644e-01,  3.3556e-01],\n",
            "          ...,\n",
            "          [-3.6078e-01,  4.1145e-03,  5.5006e-02,  ...,  2.1292e-01,\n",
            "           -1.3755e-01, -2.6359e-01],\n",
            "          [ 4.1439e-02,  5.7775e-02, -1.9868e-01,  ...,  1.0755e-01,\n",
            "            5.1876e-02,  2.0765e-02],\n",
            "          [-2.6002e-01, -2.7774e-01, -2.8022e-01,  ...,  1.0213e-01,\n",
            "            1.9812e-01,  2.8443e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.8768e-02, -6.3814e-03, -2.1442e-01,  ..., -4.2132e-02,\n",
            "           -1.7075e-02, -7.4860e-01],\n",
            "          [-8.5714e-03, -2.6206e-02,  7.8519e-02,  ...,  5.3760e-01,\n",
            "            1.1552e-01,  7.2976e-01],\n",
            "          [ 3.6170e-01, -4.6052e-01, -1.0297e-01,  ...,  2.7488e-02,\n",
            "            3.1349e-01, -2.8330e-01],\n",
            "          ...,\n",
            "          [-2.5420e-01, -3.9554e-01, -2.6676e-01,  ..., -1.0854e-01,\n",
            "            2.9405e-01,  9.2106e-02],\n",
            "          [ 3.7246e-01, -2.5592e-02,  2.2814e-01,  ...,  5.6023e-01,\n",
            "            6.4425e-01,  4.3000e-02],\n",
            "          [ 8.7002e-02,  1.5336e-01,  6.5015e-01,  ...,  2.2394e-01,\n",
            "            2.1128e-01, -3.4739e-01]],\n",
            "\n",
            "         [[-4.5156e-02, -1.2832e-01, -4.4529e-01,  ...,  5.6329e-01,\n",
            "           -4.7378e-01, -3.6758e-01],\n",
            "          [ 2.9034e-01,  2.4663e-02, -1.9480e-01,  ..., -6.3331e-01,\n",
            "            5.8388e-01,  1.7652e-01],\n",
            "          [ 1.3090e-01,  1.9670e-01,  5.5168e-02,  ..., -1.4057e-01,\n",
            "            6.2989e-01,  3.1909e-01],\n",
            "          ...,\n",
            "          [ 1.1883e-01, -4.2373e-01,  1.0341e-01,  ..., -2.7388e-01,\n",
            "           -4.6776e-01, -1.2226e-01],\n",
            "          [ 6.3241e-01,  5.9917e-02, -3.5379e-01,  ..., -2.8917e-01,\n",
            "            5.6049e-01,  7.1344e-02],\n",
            "          [ 2.9110e-01,  5.1370e-01, -4.2076e-02,  ...,  6.6927e-01,\n",
            "            1.0331e-01,  3.4768e-01]],\n",
            "\n",
            "         [[ 1.3643e-01, -2.0450e-01, -4.2130e-01,  ..., -1.0129e-01,\n",
            "           -1.3386e-01,  1.8828e-02],\n",
            "          [ 3.8949e-01,  5.7040e-02,  1.6232e-02,  ...,  4.1394e-01,\n",
            "            7.6094e-01,  1.1820e-01],\n",
            "          [-3.5278e-01,  1.5188e-01, -9.7559e-02,  ...,  9.4376e-02,\n",
            "            1.0390e-01,  5.0900e-01],\n",
            "          ...,\n",
            "          [ 9.2677e-03,  1.7137e-01,  6.1019e-02,  ..., -1.4597e-01,\n",
            "           -5.3652e-01, -4.6749e-02],\n",
            "          [-2.7739e-01,  2.8092e-01, -2.6009e-01,  ...,  5.0563e-01,\n",
            "            9.0405e-01, -1.2123e-01],\n",
            "          [ 4.4692e-01, -3.4935e-03,  1.7649e-01,  ...,  2.3739e-01,\n",
            "           -1.1740e-01,  5.5538e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
            "           -1.0905e-07, -8.3421e-08],\n",
            "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
            "           -4.3836e-08, -3.0538e-09],\n",
            "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
            "           -1.0951e-09,  4.2442e-08],\n",
            "          ...,\n",
            "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
            "           -4.7666e-08, -1.3265e-08],\n",
            "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
            "            1.0628e-07,  9.3316e-08],\n",
            "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
            "            1.7710e-07,  1.7166e-07]],\n",
            "\n",
            "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
            "           -1.3309e-07, -1.0820e-07],\n",
            "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
            "           -6.7022e-08, -2.2574e-08],\n",
            "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
            "           -7.9591e-09,  3.9750e-08],\n",
            "          ...,\n",
            "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
            "           -5.9930e-08, -1.8247e-08],\n",
            "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
            "            4.1781e-08,  4.5901e-08],\n",
            "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
            "            8.7550e-08,  9.8837e-08]],\n",
            "\n",
            "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
            "           -2.6217e-08, -1.5649e-08],\n",
            "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
            "            7.1450e-08,  9.7615e-08],\n",
            "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
            "            1.3487e-07,  1.6449e-07],\n",
            "          ...,\n",
            "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
            "            6.8382e-08,  1.1367e-07],\n",
            "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
            "            1.1723e-07,  1.4394e-07],\n",
            "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
            "            1.3333e-07,  1.5844e-07]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.6878e-01,  4.5982e-01,  1.0498e+00,  ...,  1.0345e+00,\n",
            "            8.8812e-01,  9.8657e-01],\n",
            "          [-7.2047e-01, -1.0787e+00,  1.1645e+00,  ..., -1.2167e+00,\n",
            "           -8.0417e-01, -1.0216e+00],\n",
            "          [ 1.5579e+00,  4.7814e-03, -4.9733e-01,  ...,  6.5054e-01,\n",
            "           -6.7371e-01,  4.5910e-01],\n",
            "          ...,\n",
            "          [-4.2090e-01, -3.9764e-01, -7.5572e-01,  ..., -3.6916e-01,\n",
            "           -3.3464e-01, -2.2395e-01],\n",
            "          [-1.1066e+00,  1.5042e-01, -1.1801e+00,  ..., -6.2059e-03,\n",
            "           -4.5885e-01,  1.0635e-01],\n",
            "          [ 1.2394e-02, -1.4935e+00,  4.4161e-01,  ..., -5.5401e-01,\n",
            "           -5.1308e-01, -9.6548e-01]],\n",
            "\n",
            "         [[ 5.3723e-01,  9.6725e-01,  1.4870e+00,  ..., -4.3243e-01,\n",
            "           -5.7302e-02,  3.2401e-01],\n",
            "          [-1.4528e+00, -3.0620e-01,  1.2379e+00,  ...,  5.1486e-01,\n",
            "            1.5089e+00, -3.8276e-01],\n",
            "          [-6.4374e-01, -7.4938e-01, -2.4903e-01,  ...,  3.7963e-01,\n",
            "           -6.2714e-01, -5.0412e-01],\n",
            "          ...,\n",
            "          [-7.0380e-01,  1.0316e+00,  4.6400e-01,  ...,  9.6917e-01,\n",
            "           -6.6752e-01,  8.2580e-01],\n",
            "          [-1.3620e+00, -1.4026e+00, -4.3732e-01,  ...,  7.8553e-02,\n",
            "            3.6107e-01,  6.1413e-01],\n",
            "          [ 4.9603e-01,  1.6977e-01, -6.4889e-01,  ...,  2.8817e-01,\n",
            "           -7.6210e-01, -2.5547e-01]],\n",
            "\n",
            "         [[ 5.7173e-01, -4.2262e-01,  5.1329e-01,  ...,  5.2551e-01,\n",
            "            1.3371e-01,  2.3008e-01],\n",
            "          [-7.7202e-01, -7.7555e-01, -2.2128e-01,  ...,  1.0109e+00,\n",
            "           -7.3730e-01,  5.5725e-01],\n",
            "          [-1.2232e-01, -3.0113e-01,  2.1254e-01,  ..., -2.5532e-01,\n",
            "           -8.3844e-03, -7.8509e-02],\n",
            "          ...,\n",
            "          [-2.6792e-01, -7.0102e-01,  5.7819e-01,  ...,  1.1220e-01,\n",
            "           -5.2242e-03, -5.9270e-01],\n",
            "          [ 1.2849e-02, -5.7135e-01,  4.4660e-01,  ..., -6.4372e-01,\n",
            "            2.0481e-01, -1.4274e-01],\n",
            "          [-4.7177e-01, -5.8065e-01,  1.6580e-01,  ..., -5.5332e-01,\n",
            "           -5.1441e-01, -1.3604e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0651e-01, -2.1180e-01, -4.3340e-01,  ..., -5.9478e-01,\n",
            "           -2.3090e-01, -2.5845e-01],\n",
            "          [ 3.4584e-01, -1.6848e-01, -3.2166e-01,  ..., -6.2184e-02,\n",
            "            2.5954e-01, -2.2867e-01],\n",
            "          [-9.3612e-02,  8.9835e-02, -1.1298e-01,  ..., -2.5118e-01,\n",
            "           -1.3999e-01, -2.3012e-01],\n",
            "          ...,\n",
            "          [ 4.4033e-01,  1.3196e-01,  6.8749e-01,  ...,  4.8052e-01,\n",
            "            1.0791e+00, -1.5393e-01],\n",
            "          [-2.0032e-01,  2.4743e-01,  1.9723e-02,  ...,  6.5967e-03,\n",
            "            3.1098e-01,  7.2708e-02],\n",
            "          [ 5.1153e-01,  4.4824e-01, -4.4049e-02,  ...,  3.1482e-01,\n",
            "           -5.2335e-01,  3.9288e-01]],\n",
            "\n",
            "         [[ 1.0512e-01,  6.2381e-02,  3.7501e-01,  ..., -1.5489e-01,\n",
            "            4.7365e-01, -4.1477e-01],\n",
            "          [ 1.3489e-01, -7.8230e-01,  5.8675e-02,  ...,  2.8991e-01,\n",
            "            4.2389e-02,  4.3326e-01],\n",
            "          [-2.9902e-01, -2.8390e-01, -2.5263e-01,  ..., -9.1237e-01,\n",
            "           -3.6859e-02, -1.0965e-01],\n",
            "          ...,\n",
            "          [ 2.7916e-01,  2.1498e-01,  8.9480e-01,  ...,  7.0983e-01,\n",
            "            5.6026e-01,  3.3163e-01],\n",
            "          [-8.0023e-03, -1.9591e-01,  2.6307e-01,  ...,  3.3162e-02,\n",
            "            3.7914e-02,  2.1384e-01],\n",
            "          [ 6.0917e-01, -3.2447e-01,  1.7412e-01,  ...,  1.3405e-01,\n",
            "            7.9510e-02,  3.4105e-01]],\n",
            "\n",
            "         [[-3.5408e-01,  4.4941e-01, -2.8743e-01,  ..., -3.4967e-01,\n",
            "            2.7059e-01, -7.9446e-01],\n",
            "          [ 6.2740e-01,  2.7172e-01, -6.2891e-01,  ...,  5.1970e-02,\n",
            "           -4.5848e-01, -2.0041e-01],\n",
            "          [ 3.1374e-01,  3.1123e-03,  2.7576e-01,  ..., -7.6453e-01,\n",
            "           -7.8152e-02,  2.5220e-01],\n",
            "          ...,\n",
            "          [ 1.6290e-01,  1.0189e-01,  1.9050e-01,  ...,  7.1741e-03,\n",
            "           -5.6736e-01, -9.1937e-03],\n",
            "          [ 2.5100e-01,  5.1975e-01,  1.5829e-01,  ..., -6.4206e-01,\n",
            "            3.8727e-02,  9.7995e-02],\n",
            "          [-1.6215e-01,  1.6067e-01, -1.7207e-02,  ...,  2.0041e-01,\n",
            "           -5.5379e-01, -3.7883e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.2919e-01,  4.9361e-01,  3.9905e-01,  ...,  9.1075e-01,\n",
            "            2.9102e-01,  1.4439e-01],\n",
            "          [-2.9984e-01,  5.8718e-02,  3.3227e-01,  ...,  1.8162e-01,\n",
            "            6.8037e-02, -5.8110e-02],\n",
            "          [-4.6144e-02,  6.6565e-01,  5.8468e-03,  ...,  3.8240e-01,\n",
            "            1.2928e-01,  5.8167e-01],\n",
            "          ...,\n",
            "          [-5.4272e-01,  2.4088e-01, -6.2257e-01,  ...,  8.2250e-01,\n",
            "            3.7598e-02,  2.7213e-01],\n",
            "          [-7.7738e-01, -7.2219e-01, -3.8785e-01,  ...,  4.0567e-01,\n",
            "            1.5800e-02,  3.0449e-01],\n",
            "          [-3.1451e-01,  5.0321e-01,  1.8961e-01,  ..., -6.0946e-01,\n",
            "           -1.5777e-01, -3.1201e-01]],\n",
            "\n",
            "         [[-2.6701e-01,  1.7925e-01,  2.7045e-01,  ..., -2.0909e-02,\n",
            "            4.5395e-01,  7.2094e-01],\n",
            "          [-2.5906e-01, -1.8365e-02,  6.7750e-02,  ...,  2.0126e-01,\n",
            "            4.1364e-01, -1.6048e-01],\n",
            "          [ 3.5757e-01,  3.2922e-01,  4.5662e-01,  ..., -1.0009e-02,\n",
            "            2.3705e-01, -1.7574e-01],\n",
            "          ...,\n",
            "          [ 1.4410e-01, -3.7091e-01, -2.8202e-01,  ...,  5.6385e-01,\n",
            "            1.6003e-01,  9.8709e-03],\n",
            "          [-3.1590e-01,  7.5059e-02, -2.7710e-01,  ..., -1.9598e-01,\n",
            "            1.0623e-01,  2.1622e-01],\n",
            "          [ 2.0710e-02,  2.1135e-01,  3.2010e-02,  ...,  7.2534e-01,\n",
            "            1.1387e-01, -1.3696e-01]],\n",
            "\n",
            "         [[ 2.2078e-01,  1.7062e-01,  5.2396e-01,  ...,  3.5218e-01,\n",
            "            9.2111e-01,  4.2736e-01],\n",
            "          [-3.3745e-01, -4.0411e-02,  4.6529e-01,  ..., -1.1645e-01,\n",
            "            6.0783e-02,  2.8723e-01],\n",
            "          [ 2.0651e-01,  4.5176e-01,  1.3195e-02,  ..., -1.2641e-02,\n",
            "            3.7505e-01, -1.7060e-01],\n",
            "          ...,\n",
            "          [-2.1244e-01, -4.1033e-01, -2.3519e-01,  ...,  4.3828e-01,\n",
            "            6.9957e-01,  3.9483e-01],\n",
            "          [-6.8847e-01,  1.1360e-01,  3.1249e-02,  ...,  1.3531e-02,\n",
            "            2.5054e-01, -5.1587e-01],\n",
            "          [ 1.8063e-01, -1.2289e-01,  2.9462e-01,  ...,  8.4714e-02,\n",
            "            8.6536e-02, -8.6656e-02]]]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(w)\n",
        "# Yes 意味着sgd.step()改变了w的参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVH02ucCl-Fz"
      },
      "source": [
        "32. `loss` 是否应该改变？检查第5题的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxRm0NWnl-Fz",
        "outputId": "306dab91-80ca-4b9c-f9ab-e14a402d586b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3577.2236, grad_fn=<DivBackward1>)\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "# 不会（因为它不是模型参数的一部分）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-c_aUIwl-F0"
      },
      "source": [
        "33. 将所有可训练参数的梯度清零。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VXkimI61l-F0"
      },
      "outputs": [],
      "source": [
        "model.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMdW5gu2l-F0"
      },
      "source": [
        "34. `w` 的 `grad` 属性应该是什么？验证一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBsNx0MLl-F0",
        "outputId": "f98b205a-fb83-4611-d3ac-e6cdf3a61bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(w.grad)\n",
        "# Zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5YSvHUTl-F0"
      },
      "source": [
        "35. 在不运行的情况下，判断以下代码是否会成功执行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "O_S_F0GXl-F0"
      },
      "outputs": [],
      "source": [
        "data1 = torch.zeros(1, 3, 64, 64)\n",
        "data2 = torch.ones(1, 3, 64, 64)\n",
        "\n",
        "predictions1 = model(data1)\n",
        "predictions2 = model(data2)\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels)\n",
        "loss2 = l(predictions2, labels)\n",
        "\n",
        "loss1.backward()\n",
        "loss2.backward()\n",
        "\n",
        "#可以执行成功，当计算图的中间值被释放时，loss2.backward() 将无法工作；然而，我们并未对 loss2 使用相同的中间值，所以它将能够工作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9_Uh5myl-F0"
      },
      "source": [
        "36. 判断以下代码是否会成功执行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mhGaeyfvl-F0"
      },
      "outputs": [],
      "source": [
        "data1 = torch.zeros(1, 3, 64, 64)\n",
        "data2 = torch.ones(1, 3, 64, 64)\n",
        "\n",
        "predictions1 = model(data1)\n",
        "predictions2 = model(data1)\n",
        "\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels)\n",
        "loss2 = l(predictions2, labels)\n",
        "\n",
        "loss1.backward()\n",
        "loss2.backward()\n",
        "\n",
        "# 可以执行成功，当计算图的中间值被释放时，loss2.backward() 将无法工作；然而，我们并未对 loss2 使用相同的中间值，所以它将能够正常工作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BC6xr5ol-F0"
      },
      "source": [
        "37. 判断以下代码是否会成功执行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "QePmp7Zdl-F1",
        "outputId": "7dcc08f7-1658-4ade-f0af-c61f97096a82"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-23685b0881df>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 不会成功，当计算图的中间值被释放时，loss2.backward() 将无法工作；在这里，predictions1 的中间值将已被释放。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "data1 = torch.zeros(1, 3, 64, 64)\n",
        "data2 = torch.ones(1, 3, 64, 64)\n",
        "\n",
        "predictions1 = model(data1)\n",
        "predictions2 = model(data2)\n",
        "\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels) # 注意是predictions1\n",
        "loss2 = l(predictions1, labels) # 注意是predictions1\n",
        "\n",
        "loss1.backward()\n",
        "loss2.backward()\n",
        "\n",
        "# 不会成功，当计算图的中间值被释放时，loss2.backward() 将无法工作；在这里，predictions1 的中间值将已被释放。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL0aUwVIl-F1"
      },
      "source": [
        "38. 对于不能执行的代码，你如何修改其中一个 `.backward` 行使其工作？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "89jZt2ywl-F1"
      },
      "outputs": [],
      "source": [
        "# 将第一次调用 .backward() 改为使用 retain_graph=True。\n",
        "data1 = torch.zeros(1, 3, 64, 64)\n",
        "data2 = torch.ones(1, 3, 64, 64)\n",
        "\n",
        "predictions1 = model(data1)\n",
        "predictions2 = model(data2)\n",
        "\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels) # 注意是predictions1\n",
        "loss2 = l(predictions1, labels) # 注意是predictions1\n",
        "\n",
        "loss1.backward(retain_graph=True)\n",
        "loss2.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7lWvg4ol-F1"
      },
      "source": [
        "39. 以下代码的输出是什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTV8213Ll-F1",
        "outputId": "1007cef8-d5a7-40f1-90db-66367a047a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0 0.12895947694778442\n"
          ]
        }
      ],
      "source": [
        "predictions1 = model(data)\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels)\n",
        "loss1.backward(retain_graph=True)\n",
        "\n",
        "w = model.conv1.weight.grad[0][0][0][0]\n",
        "a = w.item()\n",
        "\n",
        "loss1.backward()\n",
        "b = w.item()\n",
        "\n",
        "model.zero_grad()\n",
        "c = w.item()\n",
        "\n",
        "print(b//a,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwxnb_UUl-F1"
      },
      "source": [
        "40. 以下代码的输出是什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JSXVvAxTl-F1",
        "outputId": "493d73cb-603e-4e44-8940-9a891538ba53"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-81efb214784e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "predictions1 = model(data)\n",
        "l = torch.nn.CrossEntropyLoss()\n",
        "loss1 = l(predictions1, labels)\n",
        "loss1.backward(retain_graph=True)\n",
        "\n",
        "a = model.conv1.weight.grad[0][0][0][0]\n",
        "\n",
        "loss1.backward()\n",
        "b = model.conv1.weight.grad[0][0][0][0]\n",
        "\n",
        "model.zero_grad()\n",
        "c = model.conv1.weight.grad[0][0][0][0]\n",
        "\n",
        "print(b//a,c)\n",
        "\n",
        "# tensor(nan) 和 tensor(0)。因为 a、b、c 都引用了相同的数据。没有使用 item()。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wE0kJq2l-F1"
      },
      "source": [
        "41. 以下代码有什么问题？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thS2aPLzl-F2"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub(f.grad.data * learning_rate)\n",
        "\n",
        "# sub 调用应该改为 sub_，这样才能正确地执行预期的原地操作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7QrBAtl-F2"
      },
      "source": [
        "42. 按正确的顺序排列训练循环的以下步骤（有多种正确答案，但你在教程中会看到一种典型的设置）：以下代码的输出是什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj4AMaydl-F2"
      },
      "outputs": [],
      "source": [
        "# optimizer.step(), optimizer.zero_grad(), loss.backward(), output = net(input), loss = criterion(output, target)\n",
        "# 这是其中一种\n",
        "\n",
        "optimizer.zero_grad()\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj6mrcz0l-F2"
      },
      "source": [
        "43. 以下代码的输出是什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rNEhEPml-F2",
        "outputId": "e696804d-3fdf-49b7-d344-a00df70a980d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "net = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "target = torch.rand(1, 1000)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "orig = net.conv1.weight.clone()[0, 0, 0, 0]\n",
        "weight = net.conv1.weight[0, 0, 0, 0]\n",
        "# 1\n",
        "optimizer.zero_grad()\n",
        "print(f\"{weight == orig}\")\n",
        "\n",
        "# 2\n",
        "output = net(data)\n",
        "loss = criterion(output, target)\n",
        "print(f\"{weight == orig}\")\n",
        "\n",
        "# 3\n",
        "loss.backward()\n",
        "print(f\"{weight == orig}\")\n",
        "\n",
        "# 4\n",
        "optimizer.step()\n",
        "print(f\"{weight == orig}\")\n",
        "\n",
        "#True\n",
        "#True\n",
        "#True\n",
        "#False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYbTgkXnl-F2"
      },
      "source": [
        "44. 我们将实现一个有一个隐藏层的神经网络。这个网络将接受一个32x32的灰度图像输入，展开它，通过一个有100个输出特征的仿射变换，应用 `ReLU` 非线性，然后映射到目标类别（10）。实现初始化和前向传递，完成以下代码。使用 `nn.Linear`, `F.relu`, `torch.flatten`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vdDflju6l-F2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 在这里补充代码\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 在这里补充代码\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "zG-YynRKl-F2"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVZZPIf3l-F2"
      },
      "source": [
        "45. 用两行代码验证你能通过上述网络进行前向传递。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "mKgJ0CAll-F2"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "preds = net.forward(torch.randn(1, 3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXS5yqj4l-F3"
      },
      "source": [
        "45. 在不运行代码的情况下，猜测以下语句的结果是什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQFNfOK4l-F3",
        "outputId": "f5538f72-a643-4379-cef5-aa5229b705f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "print(len(list(net.parameters())))\n",
        "# 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ax0g49Xl-F3"
      },
      "source": [
        "47. 获取网络参数的名称"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4HLa-psl-F3",
        "outputId": "09cbea8b-f4c1-4f2e-fb8a-04831f791334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n"
          ]
        }
      ],
      "source": [
        "print([name for name, _ in net.named_parameters()]) # ['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKdJ3Wy_l-F3"
      },
      "source": [
        "48. 以下语句指的是哪个网络层？它将评估什么？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5acSpWHl-F3",
        "outputId": "71dc0206-1d37-431e-daba-fbd2035cc3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(list(net.parameters())[1].size())\n",
        "# Fc1.bias. torch.Size([100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91547sAGl-F3"
      },
      "source": [
        "49. 以下示意图包含了实现一个神经网络所需的所有信息。实现初始化和前向传递，完成以下代码。使用 `nn.Conv2d`, `nn.Linear`, `F.max_pool2d`, `F.relu`, `torch.flatten`。提示：`ReLU` 在子采样操作后和前两个全连接层之后应用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Do9CjY16l-F3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # your code here\n",
        "        return x\n",
        "\n",
        "# 以下参考答案\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # your code here\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Yc97zdl-F3"
      },
      "source": [
        "50.修改上述代码，使用 `nn.MaxPool2d` 代替 `F.max_pool2d`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "09DIpClBl-F4"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.maxpool = nn.MaxPool2d(2, 2) # 替换\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU6SM1Zkl-F4"
      },
      "source": [
        "51. 尝试通过将第一个卷积层的输出通道数从6增加到12来增加网络的宽度。怎么修改？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7GBA_b1zl-F4"
      },
      "outputs": [],
      "source": [
        "# 以下只展示init函数\n",
        "def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 12, 5)\n",
        "    self.conv2 = nn.Conv2d(12, 16, 5) # 这里我们也可以修改输入的通道\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.maxpool = nn.MaxPool2d(2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKjUocHRl-F4"
      },
      "source": [
        "### 3.分类器训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k3S6S4tl-F4"
      },
      "source": [
        "接下来，我们进入教程的最后一部分：[Cifar10教程](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)。这个教程通过以下步骤来训练一个图像分类器：\n",
        "\n",
        "- 使用torchvision加载和归一化 (normalize) CIFAR10训练和测试数据集\n",
        "- 定义一个卷积神经网络\n",
        "- 定义一个损失函数\n",
        "- 在训练数据上训练网络\n",
        "- 在测试数据上测试网络\n",
        "\n",
        "完成上述教程后，回答以下问题："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBPPDHMAl-F4"
      },
      "source": [
        "52. 以下数据集加载代码可以运行，但代码中是否有错误？这些错误的影响是什么？如何修复这些错误？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMiKq8Ahl-F4",
        "outputId": "a0ac7106-b785-4f93-c5c7-1df2d27d69eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 41521686.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose(\n",
        "   [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# 有两个错误。首先，我们没有对训练数据加载器进行随机打乱。其次，我们在测试集中加载了 CIFAR 的训练数据，而在训练集中加载了 CIFAR 的测试数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2lBtr4Ol-F4"
      },
      "source": [
        "53. 编写两行代码从数据加载器中获取随机的训练图像（假设上面的错误已经修复）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgx-15sOl-F4",
        "outputId": "541e206d-0769-432e-ec6d-f48211d0a667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# 修改代码如下\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose(\n",
        "   [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzj7yHKxl-F5"
      },
      "source": [
        "54. 以下训练代码可以运行，但代码中是否有错误（包括计算效率低下）？这些错误的影响是什么？如何修复这些错误？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdHSGKHMl-F5",
        "outputId": "2cfedc2b-c93b-477e-e53e-d310968ffe45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.301\n",
            "[2,  2000] loss: 2.302\n"
          ]
        }
      ],
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(2):    # loop over the dataset multiple times\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "      # forward + backward + optimize\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss\n",
        "      if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "          print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "          running_loss = 0.0\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "# 有两个错误。首先，循环中应该有一个 optimizer.zero_grad()。没有这个步骤，梯度将会累积。其次，running_loss 应该使用 loss.item() 进行累加；否则，每个损失仍然会是计算图的一部分，这会占用内存，因为否则各个损失值会被垃圾回收。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4d9RqVJl-F5"
      },
      "source": [
        "55. 以下评估代码可以运行，但其中是否存在错误（包括计算效率低下）？这些错误的影响是什么？如何修正这些错误？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v3uvmt7l-F5",
        "outputId": "c6fcbd9c-124a-4238-ad06-75276495fce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 11 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(images)\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "# 有两个错误。首先，应该在循环外用 torch.no_grad()，这将禁用自动求导引擎，减少内存使用并加速计算，但你将无法进行反向传播（在评估脚本中这是不需要的）。其次，我们再次遗漏了 sum() 后的 .item() 调用，这意味着张量仍然会是计算图的一部分，占用内存。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}